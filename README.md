# Image Style Transfer

This repository implements neural style transfer to apply artistic styles from one image (style image) to another (content image) using a deep learning approach. The model leverages a pretrained VGG19 network to capture and transfer visual textures and patterns, creating unique transformations.

**Note**: Due to hardware limitations, running this code might be slow on CPUs or lower-end GPUs. For faster results, use a powerful GPU (e.g., with Google Colab or a dedicated workstation).

## Contents

- [Overview](#overview)
- [Requirements](#requirements)
- [Setup](#setup)
- [Usage](#usage)

## Overview

Neural style transfer uses a deep learning model to combine the content of one image with the style of another, resulting in an image that retains the structure of the content image but with the colors, textures, and patterns of the style image. This project follows the process pioneered by Gatys et al. using a pretrained VGG19 model.

### Key Features

- Transfers visual style from an artistic image to a content image.
- Configurable weights for adjusting the impact of content vs. style.
- Intermediate losses displayed for both content and style.

## Requirements

- Python 3.x
- PyTorch
- torchvision
- PIL (Python Imaging Library)
- Matplotlib

To install the required packages, run:
```bash
pip install torch torchvision pillow matplotlib
```

## Setup

1. **Clone the repository**:
   ```bash
   git clone https://github.com/ahmdmohamedd/image-style-transfer.git
   cd image-style-transfer
   ```

2. **Download or Prepare Images**: Place a content image and a style image in the project folder. Use visually distinct images for best results, such as:
   - **Content Image**: Portraits, landscapes, cityscapes.
   - **Style Image**: Artistic works by van Gogh, Monet, or Picasso.

3. **Update Paths**: In `neural_style_transfer.ipynb`, replace `"path_to_content_image.jpg"` and `"path_to_style_image.jpg"` with the paths to your content and style images.

## Usage

Run each cell in `neural_style_transfer.ipynb`. Below is a brief description of each section:

1. **Load Libraries**: Imports necessary libraries.
2. **Image Loading and Preprocessing**: Loads and preprocesses the content and style images.
3. **Display Images**: Shows the loaded images side-by-side for comparison.
4. **Model and Layers Selection**: Loads the VGG19 model and selects layers for capturing style and content.
5. **Content and Style Loss Functions**: Defines loss functions for content and style to guide the transformation.
6. **Optimization and Style Transfer**: Runs the optimization loop to iteratively blend the style into the content image.
7. **Display Result**: Displays the final stylized image.

**Tip**: If you have hardware limitations, consider using Google Colab for GPU access.

## Output Example

The stylized image is generated by merging the structure of the content image with the patterns and colors of the style image. Due to hardware constraints, processing may take longer on CPUs or lower-end GPUs.
